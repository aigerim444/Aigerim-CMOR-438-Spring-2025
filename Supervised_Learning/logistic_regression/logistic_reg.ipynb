{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b73b73b",
   "metadata": {},
   "source": [
    "## Logistic Regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3360b5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleNeuron(object):\n",
    "    \"\"\"\n",
    "    A class used to represent a single artificial neuron. \n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    activation_function : function\n",
    "        The activation function applied to the preactivation linear combination.\n",
    "    \n",
    "    cost_function : function\n",
    "        The cost function used to measure model performance.\n",
    "\n",
    "    w_ : numpy.ndarray\n",
    "        The weights and bias of the single neuron. The last entry being the bias. \n",
    "        This attribute is created when the train method is called.\n",
    "\n",
    "    errors_: list\n",
    "        A list containing the mean sqaured error computed after each iteration \n",
    "        of stochastic gradient descent per epoch. \n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    train(self, X, y, alpha = 0.005, epochs = 50)\n",
    "        Iterates the stochastic gradient descent algorithm through each sample \n",
    "        a total of epochs number of times with learning rate alpha. The data \n",
    "        used consists of feature vectors X and associated labels y. \n",
    "\n",
    "    predict(self, X)\n",
    "        Uses the weights and bias, the feature vectors in X, and the \n",
    "        activation_function to make a y_hat prediction on each feature vector. \n",
    "    \"\"\"\n",
    "    def __init__(self, activation_function, cost_function):\n",
    "        self.activation_function = activation_function\n",
    "        self.cost_function = cost_function\n",
    "\n",
    "    def train(self, X, y, alpha = 0.005, epochs = 50):\n",
    "   \n",
    "        self.w_ = np.random.rand(1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "        N = X.shape[0]\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                error = (self.predict(xi) - target)\n",
    "                self.w_[:-1] -= alpha*error*xi\n",
    "                self.w_[-1] -= alpha*error\n",
    "                #errors += .5*((self.predict(xi) - target)**2)\n",
    "                errors += self.cost_function(self.predict(xi), target)\n",
    "            self.errors_.append(errors/N)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        preactivation = np.dot(X, self.w_[:-1]) + self.w_[-1]\n",
    "        return self.activation_function(preactivation)\n",
    "\n",
    "    def plot_cost_function(self):\n",
    "        fig, axs = plt.subplots(figsize = (10, 8))\n",
    "        axs.plot(range(1, len(self.errors_) + 1), \n",
    "                self.errors_,\n",
    "                label = \"Cost function\")\n",
    "        axs.set_xlabel(\"epochs\", fontsize = 15)\n",
    "        axs.set_ylabel(\"Cost\", fontsize = 15)\n",
    "        axs.legend(fontsize = 15)\n",
    "        axs.set_title(\"Cost Calculated after Epoch During Training\", fontsize = 18)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_decision_boundary(self, X, y, xstring=\"x\", ystring=\"y\"):\n",
    "        plt.figure(figsize = (10, 8))\n",
    "        plot_decision_regions(X, y, clf = self)\n",
    "        plt.title(\"Neuron Decision Boundary\", fontsize = 18)\n",
    "        plt.xlabel(xstring, fontsize = 15)\n",
    "        plt.ylabel(ystring, fontsize = 15)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1954cfc7",
   "metadata": {},
   "source": [
    "Now we must write a function for the binary cross entropy loss. \n",
    "Then we will create an instance of the SingleNeuron class, convert our feature measurements into ```numpy.ndarray```\n",
    "\n",
    "Then I will create a target $y$ ```numpy.ndarray``` which assigns the labels 0 and 1 to our target variable \n",
    "\n",
    "We can then pass these values into the ```SingleNeuron.train()``` method to train our logistic single neuron with stochastic gradient descent."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
